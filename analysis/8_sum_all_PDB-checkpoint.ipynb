{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58bc90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044ab802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, json\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, sys\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "\n",
    "from recipes.dataset import MCPASDataset\n",
    "\n",
    "# from analysis_util import display_mat_from_ind\n",
    "# from analysis_util import convert_len\n",
    "\n",
    "from Bio.PDB import *\n",
    "\n",
    "from pdb_util import get_chain_list, calc_dist, remove_HOH\n",
    "# get_structure_from_id, from_str_to_chain_names, get_residues_from_names\n",
    "# from pdb_util import get_cdrs_from_anarci\n",
    "# from pdb_util import get_seqs_from_residues\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "\n",
    "def display_mat_from_ind(ind, wantdisplay=False):\n",
    "    attn_output_weights1, attn_output_weights2, abseq_with_comma, peptide, ypred, sign = ATTENTION_MATRIX_DICT[ind]\n",
    "    aseq = DF_TCR.iloc[ind]['tcra']\n",
    "    bseq = DF_TCR.iloc[ind]['tcrb']\n",
    "    abseq = convert_len(aseq, MAXLENGTH_A) + convert_len(bseq, MAXLENGTH_B)\n",
    "    peptide = convert_len(DF_TCR.iloc[ind]['peptide'], max_len_epitope)\n",
    "\n",
    "\n",
    "    attn_output_weights2_list = []\n",
    "    for head_i in range(4):\n",
    "        a = attn_output_weights2[head_i]\n",
    "        dfa = pd.DataFrame(a)\n",
    "        dfa.insert(27, \"delimiter\", [0.1**9 for _ in range(len(dfa))])\n",
    "        dfa = dfa.loc[:, ((dfa!=0).sum()!=0).values]\n",
    "        dfa.columns = [f'{c}_{i}' for i,c in enumerate(list(abseq_with_comma))]\n",
    "        dfa = dfa.head(len(peptide.replace('8','')))\n",
    "        dfa.index = list(peptide.replace('8',''))\n",
    "        dfa.index = [f'{ind}_{i}' for i,ind in enumerate(dfa.index)]\n",
    "        if wantdisplay:\n",
    "            display(px.imshow(dfa, width=800, height=480))\n",
    "        attn_output_weights2_list.append(dfa)\n",
    "\n",
    "    abseq_index = convert_len(aseq, MAXLENGTH_A) + ':' + convert_len(bseq, MAXLENGTH_B)\n",
    "\n",
    "    attn_output_weights1_list = []\n",
    "    for head_i in range(4):\n",
    "        a = attn_output_weights1[head_i]\n",
    "        dfa = pd.DataFrame(a).T\n",
    "        dfa.insert(27, \"delimiter\", [0.1**9 for _ in range(len(dfa))])\n",
    "        dfa = dfa.T\n",
    "        dfa = dfa.loc[:, ((dfa!=0).sum()!=0).values]\n",
    "        dfa.index = [f'{c}_{i}' for i,c in enumerate(list(abseq_index))]\n",
    "\n",
    "        dfa.columns = [f'{ind}_{i}' for i,ind in enumerate(peptide)]\n",
    "        selector_columns = [c for c in dfa.columns if '8_' not in c]\n",
    "        selector_index = [c for c in dfa.index if '8_' not in c]\n",
    "        dfa = dfa.loc[selector_index]\n",
    "        dfa.index = [f'{c}_{i}' for i,c in enumerate(abseq_with_comma)]\n",
    "        dfa = dfa[selector_columns]\n",
    "        if wantdisplay:\n",
    "            display(px.imshow(dfa, width=800, height=480))\n",
    "        attn_output_weights1_list.append(dfa)\n",
    "    return attn_output_weights1_list, attn_output_weights2_list\n",
    "\n",
    "def convert_len(seq, maxlen):\n",
    "    if len(seq) >= maxlen:\n",
    "        return seq[:maxlen]\n",
    "    else:  # padding\n",
    "        pad = '8' * int(maxlen - len(seq))\n",
    "        return seq + pad\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7d1195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_UNK_and_take_subset(df_train):\n",
    "    df_nounk = df_train[df_train['tcra']!='UNK']\n",
    "    print(\"df_nounk.value_counts() \\n\\t \", df_nounk.sign.value_counts().to_dict())\n",
    "    print(\"df_nounk.drop_duplicates('tcrb') \\n\\t \", df_nounk.drop_duplicates('tcrb').sign.value_counts().to_dict())\n",
    "    return df_nounk\n",
    "\n",
    "\n",
    "def get_df(datapath):\n",
    "    return pd.DataFrame(pickle.load(open(datapath, \"rb\")))\n",
    "\n",
    "def get_df_from_path(p_list):\n",
    "    return pd.concat([get_df(d) for d in p_list]).reset_index(drop=True)\n",
    "\n",
    "def split_and_get_first(a):\n",
    "    if ',' in a:\n",
    "        a = a.split(',')[0]\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd67b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AACODES = pd.read_csv('/Users/kyoheikoyama/workspace/tcrpred/analysis/aa_codes.csv')\n",
    "\n",
    "AACODES['Abbreviation'] = AACODES['Abbreviation'].apply(lambda a: a.upper())\n",
    "AACODES_DICT = {row['Abbreviation']:row['1 letter abbreviation'] for i, row in AACODES.iterrows()}\n",
    "\n",
    "KFOLD_I = 0\n",
    "\n",
    "dt = \"20211029_011638\" #logdf.checkp[0].split('/')[-1]\n",
    "print('dt', dt)\n",
    "OUT_DIR = '../../../tcr_attention_cachedir'\n",
    "ATTENTION_MATRIX_DICT = pickle.load(open(f'{OUT_DIR}/{dt}_attention_matrix_dict.pickle','rb'))\n",
    "# attn_output_weights1, attn_output_weights2, abseq_with_comma, peptide, ypred, sign = ATTENTION_MATRIX_DICT[ind]\n",
    "\n",
    "p_list = [f\"../../../external_data/ERGO-II/Samples/vdjdb_train_samples.pickle\",\n",
    "          f\"../../../external_data/ERGO-II/Samples/mcpas_train_samples.pickle\", \n",
    "          '../../../external_data/ERGO-II/Samples/vdjdb_test_samples.pickle',\n",
    "          '../../../external_data/ERGO-II/Samples/mcpas_test_samples.pickle',\n",
    "         ]\n",
    "\n",
    "df_all = get_df_from_path(p_list)\n",
    "\n",
    "print(\"df_all(train).value_counts() \\n\\t\", df_all.sign.value_counts().to_dict())\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "train_index, valid_index = [\n",
    "    (train_index, valid_index) for train_index, valid_index in kf.split(df_all)\n",
    "][KFOLD_I]\n",
    "df_train, df_valid = df_all.loc[train_index], df_all.loc[valid_index]\n",
    "\n",
    "DF_TCR = df_train = remove_UNK_and_take_subset(df_train)\n",
    "dataset_train, dataset_valid = MCPASDataset(df_train), MCPASDataset(df_valid)\n",
    "\n",
    "print('len(dataset_train),', len(dataset_train), len(df_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9bd40",
   "metadata": {},
   "source": [
    "# SCEPTRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb5982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('/Users/kyoheikoyama/Downloads/sceptre_result_v2.csv')['pdb_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62cc870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sceptre_result = pd.read_csv('../../sceptre_result.csv')\n",
    "\n",
    "df_sceptre_result = df_sceptre_result[[\n",
    "    'chain1_type', 'chain2_type', 'chain1_cdr3_seq_calculated', 'chain2_cdr3_seq_calculated', \n",
    "    'epitope_seq', 'epitope_accession_IRI', 'epitope_organism_IRI', \n",
    "    'pdb_id', 'tcr_c1_pdb_chain', 'tcr_c2_pdb_chain', 'mhc_c1_pdb_chain', 'mhc_c2_pdb_chain', 'e_pdb_chain', 'pdb_cell_contact_area', 'chain1_cdr3_pdb_pos', 'chain2_cdr3_pdb_pos',\n",
    "    'calc_e_residues', 'calc_e_tcr_residues', 'calc_e_mhc_residues', 'calc_tcr_e_residues', 'calc_tcr_mhc_residues', 'calc_mhc_e_residues', 'calc_mhc_tcr_residues', 'calc_e_contact_area', 'calc_cell_contact_area'\n",
    "                                      ]]\n",
    "df_sceptre_result = pd.concat([\n",
    "    df_sceptre_result,\n",
    "    pd.DataFrame(df_sceptre_result.apply(tcr_a_or_b, axis=1))], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ac13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_sceptre_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a85f567",
   "metadata": {},
   "source": [
    "# Attention based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7869d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DF_TCR[DF_TCR['peptide'] == PEPSEQ].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLENGTH_A, MAXLENGTH_B, max_len_epitope = 28, 28, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bbb8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6d721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# attn_output_weights1_list, attn_output_weights2_list = display_mat_from_ind(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4640492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(f'aws s3 cp s3://sg-playground-kkoyama-temp/tcrpred/tcr_attention_cachedir/df_pep_{PEPSEQ}.parquet ../../../tcr_attention_cachedir/')\n",
    "\n",
    "# df_pep = pd.read_parquet(f'../../../tcr_attention_cachedir/df_pep_{PEPSEQ}.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993064ad",
   "metadata": {},
   "source": [
    "# PDB based analysis\n",
    "\n",
    "## Look at the \"auth id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDBENTRIES = [s.replace('pdb','').replace('.ent','').upper() for s in os.listdir('./pdb/')]\n",
    "\n",
    "print('len(PDBENTRIES)', len(PDBENTRIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a28c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len(PDBENTRIES)', len(PDBENTRIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa71a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "import  multiprocessing as mp\n",
    "saved_list =  [a.replace('.ent','').replace('pdb','').upper() for a in os.listdir('pdb')]\n",
    "\n",
    "pickleload = lambda p: pickle.load(open(p,\"rb\"))\n",
    "\n",
    "path = \"/Users/kyoheikoyama/workspace/tcrpred/analysis/analysis1_alldata/../DICT_PDB_Result/DICT_PDBID_2_CHAINNAMES.pickle\"\n",
    "if os.path.exists(path):\n",
    "    DICT_PDBID_2_CHAINNAMES = pickleload(path)\n",
    "    DICT_PDBID_2_RESIDUES = pickleload(\"/Users/kyoheikoyama/workspace/tcrpred/analysis/analysis1_alldata/../DICT_PDB_Result/DICT_PDBID_2_RESIDUES.pickle\")\n",
    "    DICT_PDBID_2_RESIDUES = {k:[remove_HOH(v) for v in vv] for k,vv in DICT_PDBID_2_RESIDUES.items()}\n",
    "else:\n",
    "    # DICT_PDBID_2_STRUCTURE = {pdbid:get_structure_from_id(pdbid) for pdbid in tqdm(PDBENTRIES)}\n",
    "    with mp.Pool(4) as p:\n",
    "        structs = p.map(get_structure_from_id, PDBENTRIES)\n",
    "\n",
    "    DICT_PDBID_2_STRUCTURE = {pdbid:s for pdbid, s in zip(PDBENTRIES, structs)}\n",
    "\n",
    "    temp = {pdbid:(from_str_to_chain_names(s)) for pdbid, s in \n",
    "                             tqdm(DICT_PDBID_2_STRUCTURE.items())}\n",
    "    DICT_PDBID_2_CHAINNAMES = {k:v for k, v in temp.items() if v[0] is not None}\n",
    "    DICT_PDBID_2_RESIDUES = {}\n",
    "    for p, v in tqdm(DICT_PDBID_2_CHAINNAMES.items()):\n",
    "        a, b, e = v\n",
    "        a = split_and_get_first(a)\n",
    "        b = split_and_get_first(b)\n",
    "        e = split_and_get_first(e)\n",
    "        s = DICT_PDBID_2_STRUCTURE[p]\n",
    "        DICT_PDBID_2_RESIDUES[p]  = get_residues_from_names(s, a, b, e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936a460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('count_of_pdbids', len(DICT_PDBID_2_RESIDUES))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb72e67d",
   "metadata": {},
   "source": [
    "#### \n",
    "Beta-2 microglobulin\n",
    "β₂ microglobulin also known as B2M is a component of MHC class I molecules, \n",
    "MHC class I molecules have α₁, α₂, and α₃ proteins which are present on all nucleated cells. \n",
    "In humans, the β₂ microglobulin protein is encoded by the B2M gene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312d7c7",
   "metadata": {},
   "source": [
    "# USE Anarci to get CDRs of TCR from PDB\n",
    "\n",
    "https://github.com/oxpig/ANARCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13042f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "DICT_PDBID_2_CDRS = {}\n",
    "for p, v in DICT_PDBID_2_RESIDUES.items():\n",
    "    residues_chain_alpha, residues_chain_beta, epi = v\n",
    "    residues_chain_cdr_alpha, residues_chain_cdr_beta = get_cdrs_from_anarci(\n",
    "        p, residues_chain_alpha, residues_chain_beta)\n",
    "    DICT_PDBID_2_CDRS[p] = (residues_chain_cdr_alpha, residues_chain_cdr_beta, epi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a0d2f",
   "metadata": {},
   "source": [
    "#### http://www.imgt.org/IMGTScientificChart/Nomenclature/IMGT-FRCDRdefinition.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c50f67f",
   "metadata": {},
   "source": [
    "# PDB-distance-based Visualization\n",
    "(Distance Matrix on PDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb_util import distance_mat_from_residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c57031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb_util import get_seqs_from_residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_seqs_from_residues(*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f5e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DICT_PDBID_2_DISTANCE = {}\n",
    "\n",
    "for p,v in DICT_PDBID_2_CDRS.items():\n",
    "    a,b,e = v\n",
    "    if any([vv is None or len(vv)==0 for vv in v]):\n",
    "        continue\n",
    "    else:\n",
    "        DICT_PDBID_2_DISTANCE[p] = distance_mat_from_residues(a, b, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec450c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_PDBID_2_DISTANCE[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print([AACODES_DICT[r.get_resname()]  for r in v[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a08f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pdbid in DICT_PDBID_2_CDRS.keys():\n",
    "#     if pdbid not in DICT_PDBID_2_DISTANCE:\n",
    "#         print(pdbid)\n",
    "#         print(DICT_PDBID_2_CDRS[pdbid])\n",
    "        \n",
    "#         cdr_beta = ''.join(\n",
    "#             pd.read_csv(f'anarci/{pdbid}_anarci_B.csv')[_IMGT_CDR_POS].values[0].tolist())\n",
    "#         cdr_alpha = ''.join(\n",
    "#             pd.read_csv(f'anarci/{pdbid}_anarci_D.csv')[_IMGT_CDR_POS].values[0].tolist())\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DICT_PDBID_2_RESIDUES), len(DICT_PDBID_2_CDRS), len(DICT_PDBID_2_DISTANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee61fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "from pdb_util import make_xlabel\n",
    "\n",
    "DICT_PDBID_2_MELTDIST = {}\n",
    "for p,distmat in DICT_PDBID_2_DISTANCE.items():\n",
    "    distmat_vis = distmat.drop(columns=[c for c in distmat.columns if ':' in c])\\\n",
    "        .melt(ignore_index=False).reset_index().rename(columns={'variable':'tcr', 'index':'peptide'})\n",
    "    distmat_vis = distmat_vis.sort_values(by=['peptide', 'tcr'])\n",
    "    DICT_PDBID_2_MELTDIST[p] = distmat_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6ea3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p,distmat in DICT_PDBID_2_DISTANCE.items():\n",
    "    fig = px.imshow(distmat, \n",
    "              x=distmat.columns, \n",
    "              y=distmat.index,  \n",
    "              width=1000, height=1200)\n",
    "    fig.update_layout(\n",
    "        title=f\"Residue distance in PDB {p}\",\n",
    "        xaxis_title=\"cdr_alpha:beta\",\n",
    "        yaxis_title=\"seq_epitope\",\n",
    "        autosize=False\n",
    "    )\n",
    "    fig.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc0f552",
   "metadata": {},
   "source": [
    "# Get attention from adhoc sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c7b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../../hpo_params/optuna_best.json\", \"r\") as fp:\n",
    "    hparams = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_PDBID_2_SEQUENCES_CDR = {}\n",
    "for p, cdrs in DICT_PDBID_2_CDRS.items():\n",
    "    if any([v is None or len(v)==0 for v in cdrs]):\n",
    "        continue\n",
    "    DICT_PDBID_2_SEQUENCES_CDR[p] =  get_seqs_from_residues(*cdrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(DICT_PDBID_2_SEQUENCES_CDR).T\n",
    "df = df.rename(columns={0:'tcra', 1:'tcrb', 2:'peptide'})\n",
    "df['sign']=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d047970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e712592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['peptide'].apply(len)<=25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da024b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.reset_index().rename(columns={'index':'pdbid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset = MCPASDataset(df)\n",
    "analysis_loader = torch.utils.data.DataLoader(torch_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070985db",
   "metadata": {},
   "source": [
    "## Recover model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipes.utils import get_file_paths\n",
    "from scripts.attention_extractor import get_attention_weights, Explain_TCRModel\n",
    "from recipes.model import TCRModel\n",
    "from ignite.handlers import Checkpoint\n",
    "from ignite.engine import Events, create_supervised_trainer\n",
    "n_tok = 29  # NUM_VOCAB\n",
    "n_pos1 = 62  # MAX_LEN_AB\n",
    "n_pos2 = 26  # MAX_LEN_Epitope\n",
    "n_seg = 3\n",
    "\n",
    "d_model, d_ff, n_head,n_local_encoder = hparams['d_model'], hparams['d_ff'], hparams['n_head'], hparams['n_local_encoder']\n",
    "n_global_encoder = hparams['n_global_encoder']\n",
    "dropout = hparams['dropout']\n",
    "batch_size = hparams['batch_size']\n",
    "lr=hparams['lr']\n",
    "\n",
    "explain_model = Explain_TCRModel(d_model=d_model, d_ff=d_ff, n_head=n_head, n_local_encoder=n_local_encoder, \n",
    "                                 n_global_encoder=n_global_encoder, dropout=dropout, scope=4, \n",
    "                                 n_tok=n_tok, n_pos1=n_pos1, n_pos2=n_pos2, n_seg=n_seg)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "'''Model, optim, trainer'''\n",
    "model = TCRModel(d_model=d_model, d_ff=d_ff, n_head=n_head, n_local_encoder=n_local_encoder, \n",
    "                 n_global_encoder=n_global_encoder, dropout=dropout, scope=4, \n",
    "                 n_tok=n_tok, n_pos1=n_pos1,\n",
    "                n_pos2=n_pos2, n_seg=n_seg)\n",
    "\n",
    "# Optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Loss\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0, 15.0], device=device))\n",
    "\n",
    "trainer = create_supervised_trainer(\n",
    "    model=model, optimizer=optim, loss_fn=loss_fn, device=device,\n",
    ")\n",
    "\n",
    "checkpoint_files = get_file_paths('sg-playground-kkoyama-temp', 'tcrpred/checkpoint', '', '.pt')\n",
    "checkpoint_files_withdt = [f for f in checkpoint_files if dt in f]\n",
    "CHECKPOINT_DIR = f's3://sg-playground-kkoyama-temp/tcrpred/checkpoint/{dt}'\n",
    "CHECKPOINT_PATH = checkpoint_files_withdt[0].split('/')[-1]\n",
    "\n",
    "## Get the prediction and the best model\n",
    "to_load = {'model': model, 'optimizer': optim, 'trainer': trainer}\n",
    "\n",
    "torch_check_point_local = '../../../checkpoint/'\n",
    "fro = os.path.join(CHECKPOINT_DIR, CHECKPOINT_PATH)\n",
    "if not os.path.exists(os.path.join(torch_check_point_local, CHECKPOINT_PATH)):\n",
    "    os.system(f'''aws s3 cp {fro} {torch_check_point_local}''')\n",
    "    \n",
    "checkpoint = torch.load(os.path.join(torch_check_point_local, CHECKPOINT_PATH), map_location=torch.device(device))\n",
    "\n",
    "checkpoint['trainer']['seed'] = 9\n",
    "\n",
    "Checkpoint.load_objects(to_load=to_load, checkpoint=checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3496b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLENGTH_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mat_from_result_tuple(result_tuple, aseq, bseq, peptide):\n",
    "    #abseq = convert_len(aseq, MAXLENGTH_A)convert_len(bseq, MAXLENGTH_B) \n",
    "    attn_output_weights1 = result_tuple[0]\n",
    "    attn_output_weights2 = result_tuple[1]\n",
    "    print(f\"aseq={aseq}, bseq={bseq}, peptide={peptide}\")\n",
    "    abseq_with_comma = f'{aseq}:{bseq}'\n",
    "    abseq_index = convert_len(aseq, MAXLENGTH_A) + ':' + convert_len(bseq, MAXLENGTH_B) \n",
    "    \n",
    "    attn_output_weights2_list = []\n",
    "    for head_i in range(4):\n",
    "#         print('head', head_i, attn_output_weights2[head_i].shape)\n",
    "        a = attn_output_weights2[head_i]\n",
    "        dfa = pd.DataFrame(a)\n",
    "        dfa.insert(27, \"delimiter\", [0.1**9 for _ in range(len(dfa))])\n",
    "        dfa = dfa.loc[:, ((dfa!=0).sum()!=0).values]\n",
    "        dfa.columns = list(abseq_with_comma)\n",
    "        dfa.columns = [f'{c}_{i}' for i,c in enumerate(dfa.columns)]\n",
    "        dfa = dfa.head(len(peptide.replace('8','')))\n",
    "        dfa.index = list(peptide.replace('8',''))\n",
    "        dfa.index = [f'{ind}_{i}' for i,ind in enumerate(dfa.index)]    \n",
    "        #         print('df.sum(axis=0)', dfa.sum(axis=0))\n",
    "        #         print('df.sum(axis=1)', dfa.sum(axis=1))\n",
    "        # display(px.imshow(dfa, width=800, height=480))\n",
    "        \n",
    "        axs[0,head_i].imshow(dfa, aspect='equal')\n",
    "        axs[0,head_i].set_xticks(range(len(dfa.columns)))\n",
    "        axs[0,head_i].set_yticks(range(len(dfa.index)))\n",
    "        axs[0,head_i].set_xticklabels(dfa.columns)\n",
    "        axs[0,head_i].set_yticklabels(dfa.index)\n",
    "        attn_output_weights2_list.append(dfa)\n",
    "    \n",
    "    attn_output_weights1_list = []\n",
    "    for head_i in range(4):\n",
    "#         print('head', head_i, attn_output_weights1[head_i].shape)\n",
    "        a = attn_output_weights1[head_i]\n",
    "        dfa = pd.DataFrame(a).T\n",
    "        dfa.insert(MAXLENGTH_A, \"delimiter\", [0.1**9 for _ in range(len(dfa))])\n",
    "        dfa = dfa.T\n",
    "        dfa = dfa.loc[:, ((dfa!=0).sum()!=0).values]\n",
    "        dfa.index = list(abseq_index)\n",
    "        dfa.index = [f'{c}_{i}' for i,c in enumerate(dfa.index)]\n",
    "        dfa.columns = list(convert_len(peptide, len(dfa.columns)))\n",
    "        dfa.columns = [f'{ind}_{i}' for i,ind in enumerate(dfa.columns)]\n",
    "        selector_columns = [c for c in dfa.columns if '8_' not in c]\n",
    "        selector_index = [c for c in dfa.index if '8_' not in c]\n",
    "        dfa = dfa.loc[selector_index]\n",
    "        dfa.index = [f'{c}_{i}' for i,c in enumerate(abseq_with_comma)]\n",
    "        dfa = dfa[selector_columns]\n",
    "        #         print('df.sum(axis=0)', dfa.sum(axis=0))\n",
    "        #         print('df.sum(axis=1)', dfa.sum(axis=1))\n",
    "        # display(px.imshow(dfa, width=800, height=480))\n",
    "        \n",
    "        axs[1,head_i].imshow(dfa, aspect='equal')\n",
    "        axs[1,head_i].set_xticks(range(len(dfa.columns)))\n",
    "        axs[1,head_i].set_yticks(range(len(dfa.index)))\n",
    "        axs[1,head_i].set_xticklabels(dfa.columns)\n",
    "        axs[1,head_i].set_yticklabels(dfa.index)\n",
    "        attn_output_weights1_list.append(dfa)\n",
    "    return attn_output_weights1_list, attn_output_weights2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26246c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([s[2] for s in DICT_PDBID_2_SEQUENCES_CDR.values()])), len(DICT_PDBID_2_SEQUENCES_CDR) \n",
    "len(set([s[0] for s in DICT_PDBID_2_SEQUENCES_CDR.values()])), len(DICT_PDBID_2_SEQUENCES_CDR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_PDBID_2_model_out = {}\n",
    "\n",
    "for p, (xx,yy) in zip(df.index, analysis_loader):\n",
    "    result_tuple = get_attention_weights([x.to(device) for x in xx], \n",
    "                                   model, explain_model=explain_model, device=device)\n",
    "    DICT_PDBID_2_model_out[p] = result_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICT_PDBID_2_model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84521d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "DICT_PDBID_2_Atten12 = {}\n",
    "for p, (xx,yy) in zip(df.index, analysis_loader):\n",
    "    \n",
    "    if p not in DICT_PDBID_2_model_out:\n",
    "        continue\n",
    "    print('pdbid =', p)\n",
    "    HEAD_COUNT = 4\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(60,16))\n",
    "    \n",
    "    a,b,e = DICT_PDBID_2_SEQUENCES_CDR[p]\n",
    "    attn_output_weights1_list, attn_output_weights2_list = get_mat_from_result_tuple(\n",
    "        result_tuple=DICT_PDBID_2_model_out[p], aseq=a, bseq=b, peptide=e)\n",
    "    DICT_PDBID_2_Atten12[p] = (attn_output_weights1_list, attn_output_weights2_list)\n",
    "    plt.show()\n",
    "    print('-'*100)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c68e16b",
   "metadata": {},
   "source": [
    "# Attention-based Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afd2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054742cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a analysis_util.py\n",
    "def calc_melt_df(distmat_vis, attn_output_weights1, attn_output_weights2):\n",
    "    separator = [c for c in attn_output_weights2.columns if ':' in c][0]\n",
    "    separator_pos = attn_output_weights2.columns.get_loc(separator)\n",
    "    removers = [':', 'C_0'] + \\\n",
    "        [attn_output_weights2.columns[i] for i in [separator_pos, separator_pos-1, separator_pos+1, len(attn_output_weights2.columns)-1]]\n",
    "    remove_col = [c for c in attn_output_weights2.columns if c in removers]\n",
    "    remove_ind = [c for c in attn_output_weights1.index if c in removers]\n",
    "    attn_output_weights2 = attn_output_weights2.drop(columns=remove_col)\n",
    "    attn_output_weights1 = attn_output_weights1.drop(index=remove_ind)\n",
    "    \n",
    "    attn_output_weights2_vis = attn_output_weights2.melt(ignore_index=False).reset_index().rename(columns={'variable':'tcr', 'index':'peptide'})\n",
    "    attn_output_weights2_vis= attn_output_weights2_vis.sort_values(by=['peptide', 'tcr'])\n",
    "    attn_output_weights1_vis = attn_output_weights1.T.melt(ignore_index=False).reset_index().rename(columns={'variable':'tcr', 'index':'peptide'})\n",
    "    attn_output_weights1_vis = attn_output_weights1_vis.sort_values(by=['peptide', 'tcr'])\n",
    "    \n",
    "    merged_xy_1 = pd.merge(distmat_vis, attn_output_weights1_vis, on=['peptide','tcr'], how='inner')\n",
    "    merged_xy_2 = pd.merge(distmat_vis, attn_output_weights2_vis, on=['peptide','tcr'], how='inner')\n",
    "    return merged_xy_1, merged_xy_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e727ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a analysis_util.py\n",
    "\n",
    "def show_correlation(distmat_vis, merged_xy_1, merged_xy_2, head):\n",
    "    #merged_xy_1, merged_xy_2 = calc_melt_df(distmat_vis, attn_output_weights2, attn_output_weights1)\n",
    "    assert len(merged_xy_2)!=0\n",
    "    assert len(merged_xy_1)!=0\n",
    "#     display(merged_xy_2)\n",
    "#     display(merged_xy_1)\n",
    "    x = merged_xy_2['value_x'].values\n",
    "    y = merged_xy_2['value_y'].values\n",
    "    b2, m2 = polyfit(x, y, 1)\n",
    "    axs[0, head].plot(x, b2 + m2 * x, '-')\n",
    "    axs[0, head].scatter(x, y)\n",
    "    axs[0, head].set_xlabel('distance in PDB')\n",
    "    axs[0, head].set_ylabel('attention weight value')\n",
    "    axs[0, head].set_title(f'correlation b/w distance and attention \\n (given a PEP, distribute tcr values to the sum 1.0), head {head} \\n y={b2:.3f}+{m2:.3f}* x')\n",
    "    \n",
    "    x = merged_xy_1['value_x'].values\n",
    "    y = merged_xy_1['value_y'].values\n",
    "    b1, m1 = polyfit(x, y, 1)\n",
    "    axs[1, head].plot(x, b1 + m1 * x, '-')\n",
    "    axs[1, head].scatter(x, y)\n",
    "    axs[1, head].set_xlabel('distance in PDB')\n",
    "    axs[1, head].set_ylabel('attention weight value')\n",
    "    axs[1, head].set_title(f'correlation b/w distance and attention \\n (given a TCR, distribute pep values to the sum 1.0), head {head} \\n y={b1:.3f}+{m1:.3f}* x')\n",
    "    return (b1,m1,b2,m2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be5806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def position_sorted(values):\n",
    "    sorted_values = sorted(set([c.split('_')[1]+'_'+c.split('_')[0] for c in values]))\n",
    "    return sorted_values\n",
    "\n",
    "m1_list = []\n",
    "m2_list = []\n",
    "\n",
    "HEAD_COUNT = 4\n",
    "for p in DICT_PDBID_2_model_out.keys():\n",
    "    a,b,e = DICT_PDBID_2_SEQUENCES_CDR[p]\n",
    "    print((p,a,b,e))\n",
    "\n",
    "    attn_output_weights1_list, attn_output_weights2_list = get_mat_from_result_tuple(\n",
    "        result_tuple=DICT_PDBID_2_model_out[p], aseq=a, bseq=b, peptide=e)\n",
    "\n",
    "    fig, axs = plt.subplots(2, HEAD_COUNT, figsize=(60,16))\n",
    "    for head in range(HEAD_COUNT):\n",
    "        distmat_vis = DICT_PDBID_2_MELTDIST[p]\n",
    "        assert all(attn_output_weights1_list[head].index == attn_output_weights2_list[head].columns)\n",
    "        no_comma_position_sorted = [c for c in position_sorted(attn_output_weights1_list[head].index) if ':' not in c]\n",
    "        assert position_sorted(distmat_vis['tcr'].values) == no_comma_position_sorted\n",
    "        attn_output_weights1, attn_output_weights2 = attn_output_weights1_list[head], attn_output_weights2_list[head]\n",
    "        merged_xy_1, merged_xy_2 = calc_melt_df(distmat_vis, attn_output_weights1, attn_output_weights2)\n",
    "        b1,m1,b2,m2 = show_correlation(distmat_vis, merged_xy_1, merged_xy_2, head)\n",
    "        m1_list.append(m1)\n",
    "        m2_list.append(m2)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f18e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(m1_list).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(m1_list).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(m2_list).hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99759e1",
   "metadata": {},
   "source": [
    "## Example of correlation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_PDBID_2_SEQUENCES_CDR.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '3MV7'\n",
    "HEAD_COUNT = 4\n",
    "\n",
    "a,b,e = DICT_PDBID_2_SEQUENCES_CDR[p]\n",
    "print((p,a,b,e))\n",
    "\n",
    "def position_sorted(values):\n",
    "    sorted_values = sorted(set([c.split('_')[1]+'_'+c.split('_')[0] for c in values]))\n",
    "    # print(sorted_values)\n",
    "    return sorted_values\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(60,16))    \n",
    "attn_output_weights1_list, attn_output_weights2_list = get_mat_from_result_tuple(\n",
    "    result_tuple=DICT_PDBID_2_model_out[p], aseq=a, bseq=b, peptide=e)\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(2, HEAD_COUNT, figsize=(60,16))\n",
    "for head in range(HEAD_COUNT):\n",
    "    distmat_vis = DICT_PDBID_2_MELTDIST[p]\n",
    "    assert all(attn_output_weights1_list[head].index == attn_output_weights2_list[head].columns)\n",
    "    no_comma_position_sorted = [c for c in position_sorted(attn_output_weights1_list[head].index) if ':' not in c]\n",
    "    assert position_sorted(distmat_vis['tcr'].values) == no_comma_position_sorted\n",
    "    attn_output_weights1, attn_output_weights2 = attn_output_weights1_list[head], attn_output_weights2_list[head]\n",
    "    merged_xy_1, merged_xy_2 = calc_melt_df(distmat_vis, attn_output_weights1, attn_output_weights2)\n",
    "    show_correlation(distmat_vis, merged_xy_1, merged_xy_2, head)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f949c8",
   "metadata": {},
   "source": [
    "# Sum up all the PDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45be40",
   "metadata": {},
   "source": [
    "## Only 2 sigma attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750709ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# attention = pickle.load(open('attention_GILGFVFTL.pickle','rb'))\n",
    "\n",
    "givenTCRdistributePEP_by_head = {}\n",
    "givenPEPdistributeTCR_by_head = {}\n",
    "\n",
    "for hi in tqdm(range(HEAD_COUNT)):\n",
    "    givenPEPdistributeTCR_by_head[hi] = []\n",
    "    givenTCRdistributePEP_by_head[hi] = []\n",
    "\n",
    "    for p, (a1_by_head, a2_by_head) in DICT_PDBID_2_Atten12.items():\n",
    "        distmat_vis = DICT_PDBID_2_MELTDIST[p]\n",
    "        a1, a2 = calc_melt_df(distmat_vis, a1_by_head[hi], a2_by_head[hi])\n",
    "        a1['pdbid'] = p\n",
    "        a2['pdbid'] = p\n",
    "        \n",
    "        temp1 = a1[a1['value_y'] > a1['value_y'].mean() + 5.0 * a1['value_y'].std()]\n",
    "        temp2 = a2[a2['value_y'] > a2['value_y'].mean() + 5.0 * a2['value_y'].std()]\n",
    "        \n",
    "        temp1[['tcr', 'pdbid']].drop_duplicates()\n",
    "        \n",
    "        givenTCRdistributePEP_by_head[hi] += [temp1]\n",
    "        givenPEPdistributeTCR_by_head[hi] += [temp2]\n",
    "\n",
    "fig, axs = plt.subplots(2, HEAD_COUNT, figsize=(60,16))\n",
    "for hi in range(4):\n",
    "    df1_strong_atten = pd.concat(givenTCRdistributePEP_by_head[hi])\n",
    "    df2_strong_atten = pd.concat(givenPEPdistributeTCR_by_head[hi])\n",
    "    show_correlation(distmat_vis, df1_strong_atten, df2_strong_atten, hi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef2170",
   "metadata": {},
   "source": [
    "## Only 2 sigma and PosPred Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ea130",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_ids = [k for k,v in DICT_PDBID_2_model_out.items() if DICT_PDBID_2_model_out[k][-1]>0.5]\n",
    "# attention = pickle.load(open('attention_GILGFVFTL.pickle','rb'))\n",
    "\n",
    "givenTCRdistributePEP_by_head = {}\n",
    "givenPEPdistributeTCR_by_head = {}\n",
    "\n",
    "for hi in tqdm(range(HEAD_COUNT)):\n",
    "    givenPEPdistributeTCR_by_head[hi] = []\n",
    "    givenTCRdistributePEP_by_head[hi] = []\n",
    "\n",
    "    for p, (a1_by_head, a2_by_head) in DICT_PDBID_2_Atten12.items():\n",
    "        if p not in strong_ids:\n",
    "            continue\n",
    "        else:\n",
    "            distmat_vis = DICT_PDBID_2_MELTDIST[p]\n",
    "            a1, a2 = calc_melt_df(distmat_vis, a1_by_head[hi], a2_by_head[hi])\n",
    "            a1['pdbid'] = p\n",
    "            a2['pdbid'] = p\n",
    "\n",
    "            temp1 = a1[a1['value_y'] > a1['value_y'].mean() + 5.0 * a1['value_y'].std()]\n",
    "            temp2 = a2[a2['value_y'] > a2['value_y'].mean() + 5.0 * a2['value_y'].std()]\n",
    "\n",
    "            temp1[['tcr', 'pdbid']].drop_duplicates()\n",
    "\n",
    "            givenTCRdistributePEP_by_head[hi] += [temp1]\n",
    "            givenPEPdistributeTCR_by_head[hi] += [temp2]\n",
    "\n",
    "fig, axs = plt.subplots(2, HEAD_COUNT, figsize=(60,16))\n",
    "for hi in range(4):\n",
    "    df1_strong_atten = pd.concat(givenTCRdistributePEP_by_head[hi])\n",
    "    df2_strong_atten = pd.concat(givenPEPdistributeTCR_by_head[hi])\n",
    "    show_correlation(distmat_vis, df1_strong_atten, df2_strong_atten, hi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35201c6",
   "metadata": {},
   "source": [
    "## All attention values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention = pickle.load(open('attention_GILGFVFTL.pickle','rb'))\n",
    "\n",
    "givenTCRdistributePEP_by_head = {}\n",
    "givenPEPdistributeTCR_by_head = {}\n",
    "\n",
    "for hi in tqdm(range(HEAD_COUNT)):\n",
    "    givenPEPdistributeTCR_by_head[hi] = []\n",
    "    givenTCRdistributePEP_by_head[hi] = []\n",
    "\n",
    "    for p, (a1_by_head, a2_by_head) in DICT_PDBID_2_Atten12.items():\n",
    "        distmat_vis = DICT_PDBID_2_MELTDIST[p]\n",
    "        a1, a2 = calc_melt_df(distmat_vis, a1_by_head[hi], a2_by_head[hi])\n",
    "        a1['pdbid'] = p\n",
    "        a2['pdbid'] = p\n",
    "        \n",
    "        givenTCRdistributePEP_by_head[hi] += [a1]\n",
    "        givenPEPdistributeTCR_by_head[hi] += [a2]\n",
    "\n",
    "fig, axs = plt.subplots(2, HEAD_COUNT, figsize=(60,16))\n",
    "for hi in range(4):\n",
    "    df1 = pd.concat(givenTCRdistributePEP_by_head[hi])\n",
    "    df2 = pd.concat(givenPEPdistributeTCR_by_head[hi])\n",
    "    show_correlation(distmat_vis, df1, df2, hi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91465b01",
   "metadata": {},
   "source": [
    "## 2 Group Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0358cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1_strong_atten.value_x.describe(), df1.value_x.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76169a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1_strong_atten.value_y.describe(), df1.value_y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82814e",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2946fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['pair_tcr_pdbid'] = df1[['tcr','pdbid']].apply(tuple, axis=1)\n",
    "# .isin(df1_strong_atten[['tcr','pdbid']].apply(tuple, axis=1).apply(tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df1_strong_atten = df1_strong_atten[['tcr','pdbid']].drop_duplicates() #.apply(tuple, axis=1)\n",
    "temp_df1_strong_atten['pair_tcr_pdbid'] = temp_df1_strong_atten.apply(tuple, axis=1)\n",
    "temp_df1_strong_atten['is_strong_atten'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, temp_df1_strong_atten, on=['pair_tcr_pdbid'], how='left').drop_duplicates('pair_tcr_pdbid') #['is_strong_atten'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d537587",
   "metadata": {},
   "source": [
    "## Logs of attention values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59eba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, HEAD_COUNT, figsize=(60,16))\n",
    "for hi in range(4):\n",
    "    df1 = pd.concat(givenTCRdistributePEP_by_head[hi])\n",
    "    df1['value_y'] = df1['value_y'].apply(np.log)\n",
    "    df2 = pd.concat(givenPEPdistributeTCR_by_head[hi])\n",
    "    df2['value_y'] = df2['value_y'].apply(np.log)\n",
    "    show_correlation(distmat_vis, df1, df2, hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a38abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, HEAD_COUNT, figsize=(60,16))\n",
    "for hi in range(4):\n",
    "    df1 = pd.concat(givenTCRdistributePEP_by_head[hi])\n",
    "    df1['value_x'] = df1['value_x'].apply(np.log)\n",
    "    df1['value_y'] = df1['value_y'].apply(np.log)\n",
    "    df2 = pd.concat(givenPEPdistributeTCR_by_head[hi])\n",
    "    df2['value_x'] = df2['value_x'].apply(np.log)\n",
    "    df2['value_y'] = df2['value_y'].apply(np.log)\n",
    "    show_correlation(distmat_vis, df1, df2, hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc0e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "914c8570",
   "metadata": {},
   "source": [
    "# Analysis by head after summing up values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5796554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64573dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head in range(4): #= 2\n",
    "    df = pd.concat(givenTCRdistributePEP_by_head[head])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['value_y'].describe(percentiles=np.arange(0,1,0.1)))\n",
    "percentile80 = df['value_y'].describe(percentiles=np.arange(0,1,0.1))['80%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43515b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_strong_attention'] = df['value_y'] > percentile80\n",
    "df['aa'] = df['tcr'].str.split('_').apply(lambda x: x[0])\n",
    "df['pos'] = df['tcr'].str.split('_').apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23976a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(by=['aa', 'is_strong_attention']).agg(len).iloc[:,:1].plot.bar(figsize=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26b516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(by=['pos', 'is_strong_attention']).agg(len).iloc[:,:1].plot.bar(figsize=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d1820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "381895b7",
   "metadata": {},
   "source": [
    "# PDB Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d92e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_commnad(Pymol_COMMAND, text):\n",
    "    return Pymol_COMMAND + text + '\\n'\n",
    "\n",
    "def get_command(pdbid):\n",
    "    Pymol_COMMAND = ''\n",
    "    residues_chain_cdr_alpha = DICT_PDBID_2_CDRS[pdbid][0]\n",
    "    residues_chain_cdr_beta = DICT_PDBID_2_CDRS[pdbid][1]\n",
    "\n",
    "    chain2_cdr3_pdb_pos = [r.get_full_id()[3][1] for r in residues_chain_cdr_beta]\n",
    "    chain1_cdr3_pdb_pos = [r.get_full_id()[3][1] for r in residues_chain_cdr_alpha]\n",
    "\n",
    "    ALPHA_CHAIN_NAME, BETA_CHAIN_NAME, EPITOPE_CHAIN_NAME = DICT_PDBID_2_CHAINNAMES[pdbid]\n",
    "\n",
    "    attn_output_weights1_list, attn_output_weights2_list = DICT_PDBID_2_Atten12[pdbid]\n",
    "    attention_residue_index = []\n",
    "    attention_residue_headnum = []\n",
    "    for headi in range(4):\n",
    "        atten = attn_output_weights2_list[headi]\n",
    "        good_vals = (atten > (atten.values.ravel().mean() + 5.0 * atten.values.ravel().std())).any()\n",
    "        attention_residue_index += [i for i,v in enumerate(good_vals.values) if v]\n",
    "        attention_residue_headnum += [headi for _ in range(sum(good_vals.values))]\n",
    "\n",
    "    residues_all = residues_chain_cdr_alpha + [None] + residues_chain_cdr_beta\n",
    "    attention_residue_alpha = [residues_all[i] for i in attention_residue_index if i<len(residues_chain_cdr_alpha)]\n",
    "    attention_residue_alpha_head = [attention_residue_headnum[i] for i, ri in enumerate(attention_residue_index) if ri<len(residues_chain_cdr_alpha)]\n",
    "    attention_residue_beta = [residues_all[i] for i in attention_residue_index if i>=len(residues_chain_cdr_beta)]\n",
    "    attention_residue_beta_head = [attention_residue_headnum[i] for i, ri in enumerate(attention_residue_index) if ri>=len(residues_chain_cdr_alpha)]\n",
    "    attention_pos_alpha = [r.get_full_id()[3][1] for r in attention_residue_alpha]\n",
    "    attention_pos_beta = [r.get_full_id()[3][1] for r in attention_residue_beta]\n",
    "\n",
    "    Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'fetch {pdbid};')\n",
    "    Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set seq_view, 1;')\n",
    "    Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'bg_color white;')\n",
    "\n",
    "    Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set_color blue60, [ 0, 0, 110 ];')\n",
    "    Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set_color blue30, [ 0, 0, 20 ];')\n",
    "    Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set_color red60, [ 110, 0, 0 ];')\n",
    "    Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set_color red30, [ 20, 0, 0 ];')\n",
    "\n",
    "    if len(BETA_CHAIN_NAME)==1:\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel beta_cdr3, (chain {BETA_CHAIN_NAME} and resi {chain2_cdr3_pdb_pos[0]}:{chain2_cdr3_pdb_pos[-1]});')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set cartoon_side_chain_helper, on')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'show sticks, beta_cdr3;')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color blue, (chain {BETA_CHAIN_NAME} and resi {chain2_cdr3_pdb_pos[0]}:{chain2_cdr3_pdb_pos[-1]});')\n",
    "    else:\n",
    "        for b in BETA_CHAIN_NAME.split(', '):\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel beta_cdr3, (chain {b} and resi {chain2_cdr3_pdb_pos[0]}:{chain2_cdr3_pdb_pos[-1]});')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set cartoon_side_chain_helper, on')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'show sticks, beta_cdr3;')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color blue, (chain {b} and resi {chain2_cdr3_pdb_pos[0]}:{chain2_cdr3_pdb_pos[-1]});')\n",
    "    # Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel beta_cdr2, (chain {BETA_CHAIN_NAME} and resi {chain2_cdr2_pdb_pos[0]}:{chain2_cdr2_pdb_pos[-1]});')\n",
    "    # Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color blue60, (chain {BETA_CHAIN_NAME} and resi  {chain2_cdr2_pdb_pos[0]}:{chain2_cdr2_pdb_pos[-1]});')\n",
    "    # Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel beta_cdr1, (chain {BETA_CHAIN_NAME} and resi {chain2_cdr1_pdb_pos[0]}:{chain2_cdr1_pdb_pos[-1]});')\n",
    "    # Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color blue30, (chain {BETA_CHAIN_NAME} and resi resi {chain2_cdr1_pdb_pos[0]}:{chain2_cdr1_pdb_pos[-1]});')\n",
    "\n",
    "    \n",
    "    if len(ALPHA_CHAIN_NAME)==1:        \n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel alpha_cdr3, (chain {ALPHA_CHAIN_NAME} and resi {chain1_cdr3_pdb_pos[0]}:{chain1_cdr3_pdb_pos[-1]});')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set cartoon_side_chain_helper, on')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'show sticks, alpha_cdr3;')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color red, (chain {ALPHA_CHAIN_NAME} and resi {chain1_cdr3_pdb_pos[0]}:{chain1_cdr3_pdb_pos[-1]});')\n",
    "    else:\n",
    "        for a in ALPHA_CHAIN_NAME.split(', '):\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel alpha_cdr3, (chain {a} and resi {chain1_cdr3_pdb_pos[0]}:{chain1_cdr3_pdb_pos[-1]});')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set cartoon_side_chain_helper, on')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'show sticks, alpha_cdr3;')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color red, (chain {a} and resi {chain1_cdr3_pdb_pos[0]}:{chain1_cdr3_pdb_pos[-1]});')\n",
    "\n",
    "        \n",
    "    # Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel alpha_cdr2, (chain {ALPHA_CHAIN_NAME} and resi {chain1_cdr2_pdb_pos[0]}:{chain1_cdr2_pdb_pos[-1]});')\n",
    "    # Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color red60, (chain {ALPHA_CHAIN_NAME} and resi {chain1_cdr2_pdb_pos[0]}:{chain1_cdr2_pdb_pos[-1]});')\n",
    "    # Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel alpha_cdr1, (chain {ALPHA_CHAIN_NAME} and resi {chain1_cdr1_pdb_pos[0]}:{chain1_cdr1_pdb_pos[-1]});')\n",
    "    # Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color red30, (chain {ALPHA_CHAIN_NAME} and resi {chain1_cdr1_pdb_pos[0]}:{chain1_cdr1_pdb_pos[-1]});')\n",
    "    \n",
    "    if len(EPITOPE_CHAIN_NAME)==1:\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel epitope, chain {EPITOPE_CHAIN_NAME};')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'show sticks, epitope;')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color yellow, chain {EPITOPE_CHAIN_NAME};')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'distance polar-contact, epitope, all, mode=2;')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'color black, polar-contact;')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'distance pipi-pication, epitope, all, mode=5;')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set_color gray60, [122,122,122];')\n",
    "        Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'color gray60, pipi-pication;')\n",
    "    else:\n",
    "        for e in EPITOPE_CHAIN_NAME.split(', '):\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel epitope, chain {e};')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'show sticks, epitope;')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color yellow, chain {e};')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'distance polar-contact, epitope, all, mode=2;')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'color black, polar-contact;')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'distance pipi-pication, epitope, all, mode=5;')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'set_color gray60, [122,122,122];')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, 'color gray60, pipi-pication;')\n",
    "\n",
    "\n",
    "    '''Attention'''\n",
    "    if len(ALPHA_CHAIN_NAME)==1:\n",
    "        for hi, ap in zip(attention_residue_alpha_head, attention_pos_alpha):\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel atten_a_head{hi}, (chain {ALPHA_CHAIN_NAME} and resi {ap});')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color pink, atten_a_head{hi};')\n",
    "    else:\n",
    "        for a in ALPHA_CHAIN_NAME.split(', '):\n",
    "            for hi, ap in zip(attention_residue_alpha_head, attention_pos_alpha):\n",
    "                Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel atten_a_head{hi}, (chain {a} and resi {ap});')\n",
    "                Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color pink, atten_a_head{hi};')\n",
    "        \n",
    "    if len(BETA_CHAIN_NAME)==1:\n",
    "        for hi, ap in zip(attention_residue_beta_head, attention_pos_beta):\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel atten_b_head{hi}, (chain {BETA_CHAIN_NAME} and resi {ap});')\n",
    "            Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color pink, atten_b_head{hi};')\n",
    "    else:\n",
    "        for b in BETA_CHAIN_NAME.split(', '):\n",
    "            for hi, ap in zip(attention_residue_beta_head, attention_pos_beta):\n",
    "                Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'sel atten_b_head{hi}, (chain {b} and resi {ap});')\n",
    "                Pymol_COMMAND = add_commnad(Pymol_COMMAND, f'color pink, atten_b_head{hi};')            \n",
    "    return Pymol_COMMAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b1025",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_PDBID_2_Atten12.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDBID = '5TEZ'\n",
    "print(get_command(pdbid=PDBID))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca85005",
   "metadata": {},
   "source": [
    "# Save command into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb521f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DICT_PDBID_2_Atten12.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbid = PDBID\n",
    "for pdbid in DICT_PDBID_2_Atten12.keys():\n",
    "    with open(f'./pymolcommand/{pdbid}.txt', 'w') as f:\n",
    "        f.writelines(get_command(pdbid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7c867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat /Users/kyoheikoyama/workspace/tcrpred/analysis/analysis1_alldata/pymolcommand/3MV7.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b2090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!@/Users/kyoheikoyama/workspace/tcrpred/analysis/analysis1_alldata/pymolcommand/2UWE.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c01060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98eb2153",
   "metadata": {},
   "source": [
    "# Save Dict_something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd275b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# directory = \"../DICT_PDB_Result\"\n",
    "# for name, dic in zip(\n",
    "#     [\"DICT_PDBID_2_Atten12\",\n",
    "#         \"DICT_PDBID_2_CDRS\",\n",
    "#         \"DICT_PDBID_2_CHAINNAMES\",\n",
    "#         \"DICT_PDBID_2_DISTANCE\",\n",
    "#         \"DICT_PDBID_2_MELTDIST\",\n",
    "#         \"DICT_PDBID_2_model_out\",\n",
    "#         \"DICT_PDBID_2_RESIDUES\",\n",
    "#         \"DICT_PDBID_2_SEQUENCES_CDR\",\n",
    "# #         \"DICT_PDBID_2_STRUCTURE\"\n",
    "#     ],\n",
    "#     [DICT_PDBID_2_Atten12,\n",
    "#         DICT_PDBID_2_CDRS,\n",
    "#         DICT_PDBID_2_CHAINNAMES,\n",
    "#         DICT_PDBID_2_DISTANCE,\n",
    "#         DICT_PDBID_2_MELTDIST,\n",
    "#         DICT_PDBID_2_model_out,\n",
    "#         DICT_PDBID_2_RESIDUES,\n",
    "#         DICT_PDBID_2_SEQUENCES_CDR,\n",
    "# #         DICT_PDBID_2_STRUCTURE\n",
    "#     ]):\n",
    "    \n",
    "#     pickle.dump(dic, open(f'{directory}/{name}.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3054c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcrpred",
   "language": "python",
   "name": "tcrpred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
